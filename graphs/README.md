
In the following figures, we compare the performance of QNCCL with NCCL. 

In the first figure, we compared the performance of QNCCL and NCCL in training GPT-2 on Wikitext for one epoch while changing the number of GPUs. 

![comparing performance of QNCCL and NCCL in training GPT-2 on Wikitext for one epoch while changing the number of GPUs](https://github.com/hamid-ramezani/QNCCL/blob/stochastic_quant/graphs/Figure_1.png)


In this graph, we compared the performance of QNCCL and NCCL in training BERT on MRPC for one epoch while changing the number of GPUs. 

![comparing performance of QNCCL and NCCL in training BERT on MRPC for one epoch while changing the number of GPUs](https://github.com/hamid-ramezani/QNCCL/blob/stochastic_quant/graphs/Figure_2.png)



Here, we compared the performance of QNCCL and NCCL in executing all-reduce operation. 

![comparing performance of QNCCL and NCCL in executing all-reduce operation](https://github.com/hamid-ramezani/QNCCL/blob/stochastic_quant/graphs/Figure_3.png)


